# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jpdV6DaZXTpd4oWg4fv13O6dKznLoq5q

## Implementation of a U-Net model for segmenting different kinds of blood cells from a microscopic slide image of blood sample.
"""

import tensorflow as tf
import numpy as np
import os
import random
import cv2

from google.colab.patches import cv2_imshow

from skimage.io import imread, imshow
from skimage.transform import resize
import matplotlib.pyplot as plt

from zipfile import ZipFile
file_name = '/content/Dataset_New.zip'
 
with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')

#Defining the image height and image width
IMG_H = 256
IMG_W = 256
IMG_C = 3

TRAIN_PATH = '/content/Dataset_New/train/'
TEST_PATH = '/content/Dataset_New/test/'

seed = 42
np.random.seed = seed

train_ids = sorted(next(os.walk(TRAIN_PATH))[1])
test_ids = sorted(next(os.walk(TEST_PATH))[1])
 
x_train = np.zeros((len(train_ids),IMG_H,IMG_W,IMG_C), dtype = np.uint8)
y_train = np.zeros((len(train_ids),IMG_H,IMG_W,1), dtype = np.bool)

for n, id in (enumerate(train_ids)):   
    path = TRAIN_PATH + id
    img = imread(path + '/images/' + id + '.jpg')[:,:,:IMG_C]  
    img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)
    x_train[n] = img  #Fill empty X_train with values from img
    mask = np.zeros((IMG_H, IMG_W, 1), dtype=np.bool)
    for mask_file in next(os.walk(path + '/masks/'))[2]:
        mask_ = imread(path + '/masks/' + mask_file)
        mask_ = np.expand_dims(resize(mask_, (IMG_H, IMG_W), mode='constant',  
                                      preserve_range=True), axis=-1)
        mask = np.maximum(mask, mask_)  
        y_train[n] = mask

#Resizing test images(x_test) 
x_test = np.zeros((len(test_ids), IMG_H, IMG_W, IMG_C), dtype=np.uint8)
y_test = np.zeros((len(test_ids), IMG_H, IMG_W, 1), dtype=np.bool)
sizes_test = []
for n, id in (enumerate(test_ids)):
    path = TEST_PATH + id
    img = imread(path + '/images/' + id + '.jpg')[:,:,:IMG_C]
    sizes_test.append([img.shape[0], img.shape[1]])
    img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)
    x_test[n] = img
    mask = np.zeros((IMG_H, IMG_W, 1), dtype=np.bool)
    for mask_file in next(os.walk(path + '/masks/'))[2]:
      mask1 = imread(path + '/masks/' + mask_file)
      mask1 = np.expand_dims(resize(mask1, (IMG_H, IMG_W), mode='constant',preserve_range=True), axis=-1) 
      mask = np.maximum(mask, mask1) 
      y_test[n] = mask

#visualizing some random slides
image_x = random.randint(0, len(train_ids))
imshow(x_train[image_x])
plt.show()
imshow(np.squeeze(y_train[image_x]))
plt.show()

inputs = tf.keras.layers.Input((IMG_H, IMG_W, IMG_C))
s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)

#Encoder path
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
c1 = tf.keras.layers.Dropout(0.1)(c1)
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)

c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
c2 = tf.keras.layers.Dropout(0.1)(c2)
c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)
 
c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
c3 = tf.keras.layers.Dropout(0.2)(c3)
c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)
 
c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
c4 = tf.keras.layers.Dropout(0.2)(c4)
c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)
 
c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
c5 = tf.keras.layers.Dropout(0.3)(c5)
c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)

#Decoder path 
u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
u6 = tf.keras.layers.concatenate([u6, c4])
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)
 
u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
u7 = tf.keras.layers.concatenate([u7, c3])
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)
 
u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
u8 = tf.keras.layers.concatenate([u8, c2])
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
c8 = tf.keras.layers.Dropout(0.1)(c8)
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)
 
u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
u9 = tf.keras.layers.concatenate([u9, c1], axis=3)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
c9 = tf.keras.layers.Dropout(0.1)(c9)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)
 
outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)
 
model = tf.keras.Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(x_train,y_train,batch_size=None,epochs=200,verbose=1)

model.save('U-Net_Segmentation.h5')

model.evaluate(x_test, y_test)

idx = random.randint(0, len(x_train))
 
 
preds_train = model.predict(x_train[:int(x_train.shape[0]*0.9)], verbose=1)
preds_val = model.predict(x_train[int(x_train.shape[0]*0.9):], verbose=1)
preds_test = model.predict(x_test, verbose=1)
 
 
preds_train_t = (preds_train > 0.5).astype(np.uint8)
preds_val_t = (preds_val > 0.5).astype(np.uint8)
preds_test_t = (preds_test > 0.5).astype(np.uint8)

imshow(x_test[0])
plt.show()
imshow(np.squeeze(preds_test_t[0]))
plt.show()

pred_test_t_1 = np.squeeze(preds_test_t[0])*255
plt.imshow(pred_test_t_1)

pred_test_t_2 = np.squeeze(preds_test_t[1])*255
plt.imshow(pred_test_t_2)

images = []
images.append(pred_test_t_1)
images.append(pred_test_t_2)

stack1 = np.stack((images[0],)*3,axis = -1)
stack2 = np.stack((images[1],)*3,axis = -1)

images1 = []
images1.append(stack1)
images1.append(stack2)

for i in range(0,2):
  img = x_test[i]
  prediction = images1[i]
  blended = cv2.addWeighted(img,0.5,prediction,0.5,gamma = 0.0)
  IMG_PATH = 'BLENDED_IMG_'+str(i)+'.jpg'
  cv2.imwrite(IMG_PATH,blended)

img1 = cv2.imread('/content/BLENDED_IMG_0.jpg')
img2 = cv2.imread('/content/BLENDED_IMG_1.jpg')
img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)
imshow(img1)
plt.show()
imshow(img2)
plt.show()

#Extract Bounding Boxes
def Bounding_Box(img,img_mask,img_h,img_w):
  d = (img_h,img_w)
  img = cv2.resize(img,d)
  img_mask = cv2.resize(img_mask,d)
  img_mask = cv2.cvtColor(img_mask,cv2.COLOR_BGR2GRAY)
  kernel =np.ones((10,10),dtype = np.uint8)
  img_erode = cv2.erode(img_mask,kernel,1)
  contours,hierarchy = cv2.findContours(img_erode,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)
  bound = [cv2.boundingRect(contour) for contour in contours]
  for i in bound:
    x,y,w,h = i
    cv2.rectangle(img,(x-5,y-5),((x+w),(y+h)),(0,255,0),2)

  return img

imshow(Bounding_Box(x_test[0],stack1,256,256))
plt.show()
imshow(Bounding_Box(x_test[1],stack2,256,256))
plt.show()

cv2.imwrite('1st_slide_prediction.jpg',pred_test_t_1)
cv2.imwrite('2nd_slide_prediction.jpg',pred_test_t_2)
cv2.imwrite('1st_bounding_box.jpg',Bounding_Box(x_test[0],stack1,256,256))
cv2.imwrite('2nd_bounding_box.jpg',Bounding_Box(x_test[1],stack2,256,256))